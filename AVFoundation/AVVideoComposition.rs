//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-core-foundation")]
use objc2_core_foundation::*;
#[cfg(feature = "objc2-core-graphics")]
use objc2_core_graphics::*;
#[cfg(feature = "objc2-core-media")]
use objc2_core_media::*;
use objc2_foundation::*;
#[cfg(feature = "objc2-quartz-core")]
#[cfg(not(target_os = "watchos"))]
use objc2_quartz_core::*;

use crate::*;

/// Configures policy for per frame HDR display metadata
///
/// Determines what HDR display metadata should be attached to the rendered frame.
///
/// Default.  Pass the HDR metadata through, if present on the composed frame.
///
/// AVVideoComposition may generate HDR metadata and attach it to the rendered frame.  HDR metadata generation is influenced by the color space of the rendered frame, device, and HDR metadata format platform support.  Any previously attached HDR metadata of the same metadata format will be overwritten.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionperframehdrdisplaymetadatapolicy?language=objc)
// NS_TYPED_ENUM
pub type AVVideoCompositionPerFrameHDRDisplayMetadataPolicy = NSString;

extern "C" {
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionperframehdrdisplaymetadatapolicypropagate?language=objc)
    pub static AVVideoCompositionPerFrameHDRDisplayMetadataPolicyPropagate:
        &'static AVVideoCompositionPerFrameHDRDisplayMetadataPolicy;
}

extern "C" {
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionperframehdrdisplaymetadatapolicygenerate?language=objc)
    pub static AVVideoCompositionPerFrameHDRDisplayMetadataPolicyGenerate:
        &'static AVVideoCompositionPerFrameHDRDisplayMetadataPolicy;
}

extern_class!(
    /// The AVVideoCompositionRenderContext class defines the context within which custom compositors render new output pixels buffers.
    ///
    ///
    /// An instance of AVVideoCompositionRenderContext provides size and scaling information and offers a service for efficiently providing pixel buffers from a managed pool of buffers.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocomposition?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVVideoComposition;
);

unsafe impl NSCopying for AVVideoComposition {}

unsafe impl CopyingHelper for AVVideoComposition {
    type Result = Self;
}

unsafe impl NSMutableCopying for AVVideoComposition {}

unsafe impl MutableCopyingHelper for AVVideoComposition {
    type Result = AVMutableVideoComposition;
}

unsafe impl NSObjectProtocol for AVVideoComposition {}

extern_methods!(
    unsafe impl AVVideoComposition {
        #[cfg(feature = "AVAsset")]
        /// Returns a new instance of AVVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks.
        ///
        /// Parameter `asset`: An instance of AVAsset. Ensure that the duration and tracks properties of the asset are already loaded before invoking this method.
        ///
        /// Returns: An instance of AVVideoComposition.
        ///
        /// The returned AVVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks.
        /// It will also have the following values for its properties:
        ///
        /// - If the asset has exactly one video track, the original timing of the source video track will be used. If the asset has more than one video track, and the nominal frame rate of any of video tracks is known, the reciprocal of the greatest known nominalFrameRate will be used as the value of frameDuration. Otherwise, a default framerate of 30fps is used.
        /// - If the specified asset is an instance of AVComposition, the renderSize will be set to the naturalSize of the AVComposition; otherwise the renderSize will be set to a value that encompasses all of the asset's video tracks.
        /// - A renderScale of 1.0.
        /// - A nil animationTool.
        ///
        /// If the specified asset has no video tracks, this method will return an AVVideoComposition instance with an empty collection of instructions.
        #[deprecated = "Use videoCompositionWithPropertiesOfAsset:completionHandler: instead"]
        #[method_id(videoCompositionWithPropertiesOfAsset:)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset(
            asset: &AVAsset,
        ) -> Retained<AVVideoComposition>;

        #[cfg(all(feature = "AVAsset", feature = "block2"))]
        /// Vends a new instance of AVVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks.
        ///
        /// Parameter `asset`: An instance of AVAsset.
        ///
        /// Parameter `completionHandler`: A block that is invoked when the new video composition has finished being created.  If the `videoComposition` parameter is nil, the `error` parameter describes the failure that occurred.
        ///
        /// The new AVVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks.
        /// It will also have the following values for its properties:
        ///
        /// - If the asset has exactly one video track, the original timing of the source video track will be used. If the asset has more than one video track, and the nominal frame rate of any of video tracks is known, the reciprocal of the greatest known nominalFrameRate will be used as the value of frameDuration. Otherwise, a default framerate of 30fps is used.
        /// - If the specified asset is an instance of AVComposition, the renderSize will be set to the naturalSize of the AVComposition; otherwise the renderSize will be set to a value that encompasses all of the asset's video tracks.
        /// - A renderScale of 1.0.
        /// - A nil animationTool.
        ///
        /// If the specified asset has no video tracks, this method will return an AVVideoComposition instance with an empty collection of instructions.
        #[method(videoCompositionWithPropertiesOfAsset:completionHandler:)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset_completionHandler(
            asset: &AVAsset,
            completion_handler: &block2::Block<dyn Fn(*mut AVVideoComposition, *mut NSError)>,
        );

        #[cfg(feature = "AVVideoCompositing")]
        #[method(customVideoCompositorClass)]
        pub unsafe fn customVideoCompositorClass(&self) -> Option<&'static AnyClass>;

        #[cfg(feature = "objc2-core-media")]
        #[method(frameDuration)]
        pub unsafe fn frameDuration(&self) -> CMTime;

        #[cfg(feature = "objc2-core-media")]
        #[method(sourceTrackIDForFrameTiming)]
        pub unsafe fn sourceTrackIDForFrameTiming(&self) -> CMPersistentTrackID;

        #[cfg(feature = "objc2-core-foundation")]
        #[method(renderSize)]
        pub unsafe fn renderSize(&self) -> CGSize;

        #[method(renderScale)]
        pub unsafe fn renderScale(&self) -> c_float;

        #[cfg(feature = "AVVideoCompositing")]
        #[method_id(instructions)]
        #[unsafe(method_family = none)]
        pub unsafe fn instructions(
            &self,
        ) -> Retained<NSArray<ProtocolObject<dyn AVVideoCompositionInstructionProtocol>>>;

        #[method_id(animationTool)]
        #[unsafe(method_family = none)]
        pub unsafe fn animationTool(&self)
            -> Option<Retained<AVVideoCompositionCoreAnimationTool>>;

        #[method_id(sourceSampleDataTrackIDs)]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceSampleDataTrackIDs(&self) -> Retained<NSArray<NSNumber>>;
    }
);

extern_methods!(
    /// Methods declared on superclass `NSObject`
    unsafe impl AVVideoComposition {
        #[method_id(init)]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[method_id(new)]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    }
);

extern_methods!(
    /// AVVideoCompositionColorimetery
    unsafe impl AVVideoComposition {
        #[method_id(colorPrimaries)]
        #[unsafe(method_family = none)]
        pub unsafe fn colorPrimaries(&self) -> Option<Retained<NSString>>;

        #[method_id(colorYCbCrMatrix)]
        #[unsafe(method_family = none)]
        pub unsafe fn colorYCbCrMatrix(&self) -> Option<Retained<NSString>>;

        #[method_id(colorTransferFunction)]
        #[unsafe(method_family = none)]
        pub unsafe fn colorTransferFunction(&self) -> Option<Retained<NSString>>;

        #[method_id(perFrameHDRDisplayMetadataPolicy)]
        #[unsafe(method_family = none)]
        pub unsafe fn perFrameHDRDisplayMetadataPolicy(
            &self,
        ) -> Retained<AVVideoCompositionPerFrameHDRDisplayMetadataPolicy>;
    }
);

extern_methods!(
    /// AVVideoCompositionFiltering
    unsafe impl AVVideoComposition {
        #[cfg(all(
            feature = "AVAsset",
            feature = "AVVideoCompositing",
            feature = "block2"
        ))]
        /// Returns a new instance of AVVideoComposition with values and instructions that will apply the specified handler block to video frames represented as instances of CIImage.
        ///
        /// Parameter `asset`: An instance of AVAsset. For best performance, ensure that the duration and tracks properties of the asset are already loaded before invoking this method.
        ///
        /// Returns: An instance of AVVideoComposition.
        ///
        /// The returned AVVideoComposition will cause the specified handler block to be called to filter each frame of the asset's first enabled video track. The handler block should use the properties of the provided AVAsynchronousCIImageFilteringRequest and respond using finishWithImage:context: with a "filtered" new CIImage (or the provided source image for no affect). In the event of an error, respond to the request using finishWithError:. The error can be observed via AVPlayerItemFailedToPlayToEndTimeNotification, see AVPlayerItemFailedToPlayToEndTimeErrorKey in notification payload.
        ///
        /// NOTE: The returned AVVideoComposition's properties are private and support only CIFilter-based operations. Mutations are not supported, either in the values of properties of the AVVideoComposition itself or in its private instructions. If rotations or other transformations are desired, they must be accomplished via the application of CIFilters during the execution of your specified handler.
        ///
        /// The video composition will also have the following values for its properties:
        ///
        /// - The original timing of the asset's first enabled video track will be used.
        /// - A renderSize that encompasses the asset's first enabled video track respecting the track's preferredTransform.
        /// - A renderScale of 1.0.
        ///
        /// The default CIContext has the following properties:
        ///
        /// - iOS: Device RGB color space
        /// - macOS: sRGB color space
        ///
        /// Example usage:
        ///
        /// playerItem.videoComposition = [AVVideoComposition videoCompositionWithAsset:srcAsset applyingCIFiltersWithHandler:
        /// ^(AVAsynchronousCIImageFilteringRequest *request)
        /// {
        /// NSError *err = nil;
        /// CIImage *filtered = myRenderer(request,
        /// &err
        /// );
        /// if (filtered)
        /// [request finishWithImage:filtered context:nil];
        /// else
        /// [request finishWithError:err];
        /// }];
        #[deprecated = "Use videoCompositionWithAsset:applyingCIFiltersWithHandler:completionHandler: instead"]
        #[method_id(videoCompositionWithAsset:applyingCIFiltersWithHandler:)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithAsset_applyingCIFiltersWithHandler(
            asset: &AVAsset,
            applier: &block2::Block<dyn Fn(NonNull<AVAsynchronousCIImageFilteringRequest>)>,
        ) -> Retained<AVVideoComposition>;

        #[cfg(all(
            feature = "AVAsset",
            feature = "AVVideoCompositing",
            feature = "block2"
        ))]
        /// Vends a new instance of AVVideoComposition with values and instructions that will apply the specified handler block to video frames represented as instances of CIImage.
        ///
        /// Parameter `asset`: An instance of AVAsset.
        ///
        /// Parameter `completionHandler`: A block that is invoked when the new video composition has finished being created.  If the `videoComposition` parameter is nil, the `error` parameter describes the failure that occurred.
        ///
        /// The new AVVideoComposition will cause the specified handler block to be called to filter each frame of the asset's first enabled video track. The handler block should use the properties of the provided AVAsynchronousCIImageFilteringRequest and respond using finishWithImage:context: with a "filtered" new CIImage (or the provided source image for no affect). In the event of an error, respond to the request using finishWithError:. The error can be observed via AVPlayerItemFailedToPlayToEndTimeNotification, see AVPlayerItemFailedToPlayToEndTimeErrorKey in notification payload.
        ///
        /// NOTE: The returned AVVideoComposition's properties are private and support only CIFilter-based operations. Mutations are not supported, either in the values of properties of the AVVideoComposition itself or in its private instructions. If rotations or other transformations are desired, they must be accomplished via the application of CIFilters during the execution of your specified handler.
        ///
        /// The video composition will also have the following values for its properties:
        ///
        /// - The original timing of the asset's first enabled video track will be used.
        /// - A renderSize that encompasses the asset's first enabled video track respecting the track's preferredTransform.
        /// - A renderScale of 1.0.
        ///
        /// The default CIContext has the following properties:
        ///
        /// - iOS: Device RGB color space
        /// - macOS: sRGB color space
        ///
        /// Example usage:
        ///
        /// [AVVideoComposition videoCompositionWithAsset:srcAsset applyingCIFiltersWithHandler:
        /// ^(AVAsynchronousCIImageFilteringRequest *request)
        /// {
        /// NSError *err = nil;
        /// CIImage *filtered = myRenderer(request,
        /// &err
        /// );
        /// if (filtered)
        /// [request finishWithImage:filtered context:nil];
        /// else
        /// [request finishWithError:err];
        /// } completionHandler:
        /// ^(AVVideoComposition * _Nullable videoComposition, NSError * _Nullable error)
        /// {
        /// if (videoComposition != nil) {
        /// playerItem.videoComposition = videoComposition
        /// else {
        /// // handle error
        /// }];
        #[method(videoCompositionWithAsset:applyingCIFiltersWithHandler:completionHandler:)]
        pub unsafe fn videoCompositionWithAsset_applyingCIFiltersWithHandler_completionHandler(
            asset: &AVAsset,
            applier: &block2::Block<dyn Fn(NonNull<AVAsynchronousCIImageFilteringRequest>)>,
            completion_handler: &block2::Block<dyn Fn(*mut AVVideoComposition, *mut NSError)>,
        );
    }
);

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition?language=objc)
    #[unsafe(super(AVVideoComposition, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVMutableVideoComposition;
);

unsafe impl NSCopying for AVMutableVideoComposition {}

unsafe impl CopyingHelper for AVMutableVideoComposition {
    type Result = AVVideoComposition;
}

unsafe impl NSMutableCopying for AVMutableVideoComposition {}

unsafe impl MutableCopyingHelper for AVMutableVideoComposition {
    type Result = Self;
}

unsafe impl NSObjectProtocol for AVMutableVideoComposition {}

extern_methods!(
    unsafe impl AVMutableVideoComposition {
        #[method_id(videoComposition)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoComposition() -> Retained<AVMutableVideoComposition>;

        #[cfg(feature = "AVAsset")]
        /// Returns a new instance of AVMutableVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks.
        ///
        /// Parameter `asset`: An instance of AVAsset. For best performance, ensure that the duration and tracks properties of the asset are already loaded before invoking this method.
        ///
        /// Returns: An instance of AVMutableVideoComposition.
        ///
        /// The returned AVMutableVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks. The client can set sourceTrackIDForFrameTiming to kCMPersistentTrackID_Invalid and frameDuration to an appropriate value in order to specify the maximum output frame rate independent of the source track timing.
        /// It will also have the following values for its properties:
        ///
        /// - If the asset has exactly one video track, the original timing of the source video track will be used. If the asset has more than one video track, and the nominal frame rate of any of video tracks is known, the reciprocal of the greatest known nominalFrameRate will be used as the value of frameDuration. Otherwise, a default framerate of 30fps is used.
        /// - If the specified asset is an instance of AVComposition, the renderSize will be set to the naturalSize of the AVComposition; otherwise the renderSize will be set to a value that encompasses all of the asset's video tracks.
        /// - A renderScale of 1.0.
        /// - A nil animationTool.
        ///
        /// If the specified asset has no video tracks, this method will return an AVMutableVideoComposition instance with an empty collection of instructions.
        #[deprecated = "Use videoCompositionWithPropertiesOfAsset:completionHandler: instead"]
        #[method_id(videoCompositionWithPropertiesOfAsset:)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset(
            asset: &AVAsset,
        ) -> Retained<AVMutableVideoComposition>;

        #[cfg(all(feature = "AVAsset", feature = "block2"))]
        /// Vends a new instance of AVMutableVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks.
        ///
        /// Parameter `asset`: An instance of AVAsset.
        ///
        /// Parameter `completionHandler`: A block that is invoked when the new video composition has finished being created.  If the `videoComposition` parameter is nil, the `error` parameter describes the failure that occurred.
        ///
        /// The new AVMutableVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks. The client can set sourceTrackIDForFrameTiming to kCMPersistentTrackID_Invalid and frameDuration to an appropriate value in order to specify the maximum output frame rate independent of the source track timing.
        /// It will also have the following values for its properties:
        ///
        /// - If the asset has exactly one video track, the original timing of the source video track will be used. If the asset has more than one video track, and the nominal frame rate of any of video tracks is known, the reciprocal of the greatest known nominalFrameRate will be used as the value of frameDuration. Otherwise, a default framerate of 30fps is used.
        /// - If the specified asset is an instance of AVComposition, the renderSize will be set to the naturalSize of the AVComposition; otherwise the renderSize will be set to a value that encompasses all of the asset's video tracks.
        /// - A renderScale of 1.0.
        /// - A nil animationTool.
        ///
        /// If the specified asset has no video tracks, this method will return an AVMutableVideoComposition instance with an empty collection of instructions.
        #[method(videoCompositionWithPropertiesOfAsset:completionHandler:)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset_completionHandler(
            asset: &AVAsset,
            completion_handler: &block2::Block<
                dyn Fn(*mut AVMutableVideoComposition, *mut NSError),
            >,
        );

        #[cfg(feature = "AVAsset")]
        /// Returns a new instance of AVMutableVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks, and also overrides default properties with those from a prototypeInstruction.
        ///
        /// Parameter `asset`: An instance of AVAsset. For best performance, ensure that the duration and tracks properties of the asset are already loaded before invoking this method.
        ///
        /// Parameter `prototypeInstruction`: Custom instructions that the client can choose to override.
        ///
        /// Returns: An instance of AVMutableVideoComposition.
        ///
        /// Also see videoCompositionWithPropertiesOfAsset:.
        /// The returned AVVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks. Anything not pertaining to spatial layout and timing, such as background color for their composition or post-processing behaviors, is eligible to be specified via a prototype instruction.
        /// Example: To add a background color,
        /// myPrototypeInstruction = [[AVMutableVideoCompositionInstruction alloc] init];
        /// myPrototypeInstruction.backgroundColor = myCGColorRef; // Do not use constant CGColorRef colors here.
        /// myVideoComposition = [AVVideoComposition videoCompositionWithPropertiesOfAsset:myAsset prototypeInstruction:myPrototypeInstruction];
        #[deprecated = "Use videoCompositionWithPropertiesOfAsset:prototypeInstruction:completionHandler: instead"]
        #[method_id(videoCompositionWithPropertiesOfAsset:prototypeInstruction:)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset_prototypeInstruction(
            asset: &AVAsset,
            prototype_instruction: &AVVideoCompositionInstruction,
        ) -> Retained<AVMutableVideoComposition>;

        #[cfg(all(feature = "AVAsset", feature = "block2"))]
        /// Vends a new instance of AVMutableVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks, and also overrides default properties with those from a prototypeInstruction.
        ///
        /// Parameter `asset`: An instance of AVAsset.
        ///
        /// Parameter `prototypeInstruction`: Custom instructions that the client can choose to override.
        ///
        /// Parameter `completionHandler`: A block that is invoked when the new video composition has finished being created.  If the `videoComposition` parameter is nil, the `error` parameter describes the failure that occurred.
        ///
        /// Also see videoCompositionWithPropertiesOfAsset:completionHandler:.
        /// The new AVMutableVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks. Anything not pertaining to spatial layout and timing, such as background color for their composition or post-processing behaviors, is eligible to be specified via a prototype instruction.
        /// Example: To add a background color,
        /// myPrototypeInstruction = [[AVMutableVideoCompositionInstruction alloc] init];
        /// myPrototypeInstruction.backgroundColor = myCGColorRef; // Do not use constant CGColorRef colors here.
        /// myVideoComposition = [AVVideoComposition videoCompositionWithPropertiesOfAsset:myAsset prototypeInstruction:myPrototypeInstruction completionHandler:^(AVMutableVideoComposition * _Nullable myVideoComposition, NSError * _Nullable error) {
        /// if (myVideoComposition != nil) {
        /// // use myVideoComposition
        /// }
        /// else {
        /// // handle error
        /// }
        /// }];
        #[method(videoCompositionWithPropertiesOfAsset:prototypeInstruction:completionHandler:)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset_prototypeInstruction_completionHandler(
            asset: &AVAsset,
            prototype_instruction: &AVVideoCompositionInstruction,
            completion_handler: &block2::Block<
                dyn Fn(*mut AVMutableVideoComposition, *mut NSError),
            >,
        );

        #[cfg(feature = "AVVideoCompositing")]
        #[method(customVideoCompositorClass)]
        pub unsafe fn customVideoCompositorClass(&self) -> Option<&'static AnyClass>;

        #[cfg(feature = "AVVideoCompositing")]
        /// Setter for [`customVideoCompositorClass`][Self::customVideoCompositorClass].
        #[method(setCustomVideoCompositorClass:)]
        pub unsafe fn setCustomVideoCompositorClass(
            &self,
            custom_video_compositor_class: Option<&AnyClass>,
        );

        #[cfg(feature = "objc2-core-media")]
        #[method(frameDuration)]
        pub unsafe fn frameDuration(&self) -> CMTime;

        #[cfg(feature = "objc2-core-media")]
        /// Setter for [`frameDuration`][Self::frameDuration].
        #[method(setFrameDuration:)]
        pub unsafe fn setFrameDuration(&self, frame_duration: CMTime);

        #[cfg(feature = "objc2-core-media")]
        #[method(sourceTrackIDForFrameTiming)]
        pub unsafe fn sourceTrackIDForFrameTiming(&self) -> CMPersistentTrackID;

        #[cfg(feature = "objc2-core-media")]
        /// Setter for [`sourceTrackIDForFrameTiming`][Self::sourceTrackIDForFrameTiming].
        #[method(setSourceTrackIDForFrameTiming:)]
        pub unsafe fn setSourceTrackIDForFrameTiming(
            &self,
            source_track_id_for_frame_timing: CMPersistentTrackID,
        );

        #[cfg(feature = "objc2-core-foundation")]
        #[method(renderSize)]
        pub unsafe fn renderSize(&self) -> CGSize;

        #[cfg(feature = "objc2-core-foundation")]
        /// Setter for [`renderSize`][Self::renderSize].
        #[method(setRenderSize:)]
        pub unsafe fn setRenderSize(&self, render_size: CGSize);

        #[method(renderScale)]
        pub unsafe fn renderScale(&self) -> c_float;

        /// Setter for [`renderScale`][Self::renderScale].
        #[method(setRenderScale:)]
        pub unsafe fn setRenderScale(&self, render_scale: c_float);

        #[cfg(feature = "AVVideoCompositing")]
        #[method_id(instructions)]
        #[unsafe(method_family = none)]
        pub unsafe fn instructions(
            &self,
        ) -> Retained<NSArray<ProtocolObject<dyn AVVideoCompositionInstructionProtocol>>>;

        #[cfg(feature = "AVVideoCompositing")]
        /// Setter for [`instructions`][Self::instructions].
        #[method(setInstructions:)]
        pub unsafe fn setInstructions(
            &self,
            instructions: &NSArray<ProtocolObject<dyn AVVideoCompositionInstructionProtocol>>,
        );

        #[method_id(animationTool)]
        #[unsafe(method_family = none)]
        pub unsafe fn animationTool(&self)
            -> Option<Retained<AVVideoCompositionCoreAnimationTool>>;

        /// Setter for [`animationTool`][Self::animationTool].
        #[method(setAnimationTool:)]
        pub unsafe fn setAnimationTool(
            &self,
            animation_tool: Option<&AVVideoCompositionCoreAnimationTool>,
        );

        #[method_id(sourceSampleDataTrackIDs)]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceSampleDataTrackIDs(&self) -> Retained<NSArray<NSNumber>>;

        /// Setter for [`sourceSampleDataTrackIDs`][Self::sourceSampleDataTrackIDs].
        #[method(setSourceSampleDataTrackIDs:)]
        pub unsafe fn setSourceSampleDataTrackIDs(
            &self,
            source_sample_data_track_i_ds: &NSArray<NSNumber>,
        );
    }
);

extern_methods!(
    /// Methods declared on superclass `NSObject`
    unsafe impl AVMutableVideoComposition {
        #[method_id(init)]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[method_id(new)]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    }
);

extern_methods!(
    /// AVMutableVideoCompositionColorimetery
    unsafe impl AVMutableVideoComposition {
        #[method_id(colorPrimaries)]
        #[unsafe(method_family = none)]
        pub unsafe fn colorPrimaries(&self) -> Option<Retained<NSString>>;

        /// Setter for [`colorPrimaries`][Self::colorPrimaries].
        #[method(setColorPrimaries:)]
        pub unsafe fn setColorPrimaries(&self, color_primaries: Option<&NSString>);

        #[method_id(colorYCbCrMatrix)]
        #[unsafe(method_family = none)]
        pub unsafe fn colorYCbCrMatrix(&self) -> Option<Retained<NSString>>;

        /// Setter for [`colorYCbCrMatrix`][Self::colorYCbCrMatrix].
        #[method(setColorYCbCrMatrix:)]
        pub unsafe fn setColorYCbCrMatrix(&self, color_y_cb_cr_matrix: Option<&NSString>);

        #[method_id(colorTransferFunction)]
        #[unsafe(method_family = none)]
        pub unsafe fn colorTransferFunction(&self) -> Option<Retained<NSString>>;

        /// Setter for [`colorTransferFunction`][Self::colorTransferFunction].
        #[method(setColorTransferFunction:)]
        pub unsafe fn setColorTransferFunction(&self, color_transfer_function: Option<&NSString>);

        #[method_id(perFrameHDRDisplayMetadataPolicy)]
        #[unsafe(method_family = none)]
        pub unsafe fn perFrameHDRDisplayMetadataPolicy(
            &self,
        ) -> Retained<AVVideoCompositionPerFrameHDRDisplayMetadataPolicy>;

        /// Setter for [`perFrameHDRDisplayMetadataPolicy`][Self::perFrameHDRDisplayMetadataPolicy].
        #[method(setPerFrameHDRDisplayMetadataPolicy:)]
        pub unsafe fn setPerFrameHDRDisplayMetadataPolicy(
            &self,
            per_frame_hdr_display_metadata_policy: &AVVideoCompositionPerFrameHDRDisplayMetadataPolicy,
        );
    }
);

extern_methods!(
    /// AVMutableVideoCompositionFiltering
    unsafe impl AVMutableVideoComposition {
        #[cfg(all(
            feature = "AVAsset",
            feature = "AVVideoCompositing",
            feature = "block2"
        ))]
        /// Returns a new instance of AVMutableVideoComposition with values and instructions that will apply the specified handler block to video frames represented as instances of CIImage.
        ///
        /// Parameter `asset`: An instance of AVAsset. For best performance, ensure that the duration and tracks properties of the asset are already loaded before invoking this method.
        ///
        /// Returns: An instance of AVMutableVideoComposition.
        ///
        /// The returned AVMutableVideoComposition will cause the specified handler block to be called to filter each frame of the asset's first enabled video track. The handler block should use the properties of the provided AVAsynchronousCIImageFilteringRequest and respond using finishWithImage:context: with a "filtered" new CIImage (or the provided source image for no affect). In the event of an error, respond to the request using finishWithError:. The error can be observed via AVPlayerItemFailedToPlayToEndTimeNotification, see AVPlayerItemFailedToPlayToEndTimeErrorKey in notification payload. The client can set sourceTrackIDForFrameTiming to kCMPersistentTrackID_Invalid and frameDuration to an appropriate value in order to specify the maximum output frame rate independent of the source track timing.
        ///
        /// The video composition will also have the following values for its properties:
        ///
        /// - The original timing of the asset's first enabled video track will be used.
        /// - A renderSize that encompasses the asset's first enabled video track respecting the track's preferredTransform.
        /// - A renderScale of 1.0.
        ///
        /// The default CIContext has the following properties:
        ///
        /// - iOS: Device RGB color space
        /// - macOS: sRGB color space
        ///
        /// Example usage:
        ///
        /// playerItem.videoComposition = [AVMutableVideoComposition videoCompositionWithAsset:srcAsset applyingCIFiltersWithHandler:
        /// ^(AVAsynchronousCIImageFilteringRequest *request)
        /// {
        /// NSError *err = nil;
        /// CIImage *filtered = myRenderer(request,
        /// &err
        /// );
        /// if (filtered)
        /// [request finishWithImage:filtered context:nil];
        /// else
        /// [request finishWithError:err];
        /// }];
        #[deprecated = "Use videoCompositionWithAsset:applyingCIFiltersWithHandler:completionHandler: instead"]
        #[method_id(videoCompositionWithAsset:applyingCIFiltersWithHandler:)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithAsset_applyingCIFiltersWithHandler(
            asset: &AVAsset,
            applier: &block2::Block<dyn Fn(NonNull<AVAsynchronousCIImageFilteringRequest>)>,
        ) -> Retained<AVMutableVideoComposition>;

        #[cfg(all(
            feature = "AVAsset",
            feature = "AVVideoCompositing",
            feature = "block2"
        ))]
        /// Vends a new instance of AVMutableVideoComposition with values and instructions that will apply the specified handler block to video frames represented as instances of CIImage.
        ///
        /// Parameter `asset`: An instance of AVAsset.
        ///
        /// Parameter `completionHandler`: A block that is invoked when the new video composition has finished being created.  If the `videoComposition` parameter is nil, the `error` parameter describes the failure that occurred.
        ///
        /// The new AVMutableVideoComposition will cause the specified handler block to be called to filter each frame of the asset's first enabled video track. The handler block should use the properties of the provided AVAsynchronousCIImageFilteringRequest and respond using finishWithImage:context: with a "filtered" new CIImage (or the provided source image for no affect). In the event of an error, respond to the request using finishWithError:. The error can be observed via AVPlayerItemFailedToPlayToEndTimeNotification, see AVPlayerItemFailedToPlayToEndTimeErrorKey in notification payload. The client can set sourceTrackIDForFrameTiming to kCMPersistentTrackID_Invalid and frameDuration to an appropriate value in order to specify the maximum output frame rate independent of the source track timing.
        ///
        /// The video composition will also have the following values for its properties:
        ///
        /// - The original timing of the asset's first enabled video track will be used.
        /// - A renderSize that encompasses the asset's first enabled video track respecting the track's preferredTransform.
        /// - A renderScale of 1.0.
        ///
        /// The default CIContext has the following properties:
        ///
        /// - iOS: Device RGB color space
        /// - macOS: sRGB color space
        ///
        /// Example usage:
        ///
        /// [AVMutableVideoComposition videoCompositionWithAsset:srcAsset applyingCIFiltersWithHandler:
        /// ^(AVAsynchronousCIImageFilteringRequest *request)
        /// {
        /// NSError *err = nil;
        /// CIImage *filtered = myRenderer(request,
        /// &err
        /// );
        /// if (filtered)
        /// [request finishWithImage:filtered context:nil];
        /// else
        /// [request finishWithError:err];
        /// } completionHandler:
        /// ^(AVMutableVideoComposition * _Nullable videoComposition, NSError * _Nullable error)
        /// {
        /// if (videoComposition != nil) {
        /// playerItem.videoComposition = videoComposition
        /// else {
        /// // handle error
        /// }];
        #[method(videoCompositionWithAsset:applyingCIFiltersWithHandler:completionHandler:)]
        pub unsafe fn videoCompositionWithAsset_applyingCIFiltersWithHandler_completionHandler(
            asset: &AVAsset,
            applier: &block2::Block<dyn Fn(NonNull<AVAsynchronousCIImageFilteringRequest>)>,
            completion_handler: &block2::Block<
                dyn Fn(*mut AVMutableVideoComposition, *mut NSError),
            >,
        );
    }
);

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositioninstruction?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVVideoCompositionInstruction;
);

#[cfg(feature = "AVVideoCompositing")]
unsafe impl AVVideoCompositionInstructionProtocol for AVVideoCompositionInstruction {}

unsafe impl NSCoding for AVVideoCompositionInstruction {}

unsafe impl NSCopying for AVVideoCompositionInstruction {}

unsafe impl CopyingHelper for AVVideoCompositionInstruction {
    type Result = Self;
}

unsafe impl NSMutableCopying for AVVideoCompositionInstruction {}

unsafe impl MutableCopyingHelper for AVVideoCompositionInstruction {
    type Result = AVMutableVideoCompositionInstruction;
}

unsafe impl NSObjectProtocol for AVVideoCompositionInstruction {}

unsafe impl NSSecureCoding for AVVideoCompositionInstruction {}

extern_methods!(
    unsafe impl AVVideoCompositionInstruction {
        #[cfg(feature = "objc2-core-media")]
        #[method(timeRange)]
        pub unsafe fn timeRange(&self) -> CMTimeRange;

        #[cfg(feature = "objc2-core-graphics")]
        #[method_id(backgroundColor)]
        #[unsafe(method_family = none)]
        pub unsafe fn backgroundColor(&self) -> Option<Retained<CGColor>>;

        #[method_id(layerInstructions)]
        #[unsafe(method_family = none)]
        pub unsafe fn layerInstructions(
            &self,
        ) -> Retained<NSArray<AVVideoCompositionLayerInstruction>>;

        #[method(enablePostProcessing)]
        pub unsafe fn enablePostProcessing(&self) -> bool;

        #[method_id(requiredSourceTrackIDs)]
        #[unsafe(method_family = none)]
        pub unsafe fn requiredSourceTrackIDs(&self) -> Retained<NSArray<NSValue>>;

        #[cfg(feature = "objc2-core-media")]
        #[method(passthroughTrackID)]
        pub unsafe fn passthroughTrackID(&self) -> CMPersistentTrackID;

        #[method_id(requiredSourceSampleDataTrackIDs)]
        #[unsafe(method_family = none)]
        pub unsafe fn requiredSourceSampleDataTrackIDs(&self) -> Retained<NSArray<NSNumber>>;
    }
);

extern_methods!(
    /// Methods declared on superclass `NSObject`
    unsafe impl AVVideoCompositionInstruction {
        #[method_id(init)]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[method_id(new)]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    }
);

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositioninstruction?language=objc)
    #[unsafe(super(AVVideoCompositionInstruction, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVMutableVideoCompositionInstruction;
);

#[cfg(feature = "AVVideoCompositing")]
unsafe impl AVVideoCompositionInstructionProtocol for AVMutableVideoCompositionInstruction {}

unsafe impl NSCoding for AVMutableVideoCompositionInstruction {}

unsafe impl NSCopying for AVMutableVideoCompositionInstruction {}

unsafe impl CopyingHelper for AVMutableVideoCompositionInstruction {
    type Result = AVVideoCompositionInstruction;
}

unsafe impl NSMutableCopying for AVMutableVideoCompositionInstruction {}

unsafe impl MutableCopyingHelper for AVMutableVideoCompositionInstruction {
    type Result = Self;
}

unsafe impl NSObjectProtocol for AVMutableVideoCompositionInstruction {}

unsafe impl NSSecureCoding for AVMutableVideoCompositionInstruction {}

extern_methods!(
    unsafe impl AVMutableVideoCompositionInstruction {
        #[method_id(videoCompositionInstruction)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionInstruction() -> Retained<Self>;

        #[cfg(feature = "objc2-core-media")]
        #[method(timeRange)]
        pub unsafe fn timeRange(&self) -> CMTimeRange;

        #[cfg(feature = "objc2-core-media")]
        /// Setter for [`timeRange`][Self::timeRange].
        #[method(setTimeRange:)]
        pub unsafe fn setTimeRange(&self, time_range: CMTimeRange);

        #[cfg(feature = "objc2-core-graphics")]
        #[method_id(backgroundColor)]
        #[unsafe(method_family = none)]
        pub unsafe fn backgroundColor(&self) -> Option<Retained<CGColor>>;

        #[cfg(feature = "objc2-core-graphics")]
        /// Setter for [`backgroundColor`][Self::backgroundColor].
        #[method(setBackgroundColor:)]
        pub unsafe fn setBackgroundColor(&self, background_color: Option<&CGColor>);

        #[method_id(layerInstructions)]
        #[unsafe(method_family = none)]
        pub unsafe fn layerInstructions(
            &self,
        ) -> Retained<NSArray<AVVideoCompositionLayerInstruction>>;

        /// Setter for [`layerInstructions`][Self::layerInstructions].
        #[method(setLayerInstructions:)]
        pub unsafe fn setLayerInstructions(
            &self,
            layer_instructions: &NSArray<AVVideoCompositionLayerInstruction>,
        );

        #[method(enablePostProcessing)]
        pub unsafe fn enablePostProcessing(&self) -> bool;

        /// Setter for [`enablePostProcessing`][Self::enablePostProcessing].
        #[method(setEnablePostProcessing:)]
        pub unsafe fn setEnablePostProcessing(&self, enable_post_processing: bool);

        #[method_id(requiredSourceSampleDataTrackIDs)]
        #[unsafe(method_family = none)]
        pub unsafe fn requiredSourceSampleDataTrackIDs(&self) -> Retained<NSArray<NSNumber>>;

        /// Setter for [`requiredSourceSampleDataTrackIDs`][Self::requiredSourceSampleDataTrackIDs].
        #[method(setRequiredSourceSampleDataTrackIDs:)]
        pub unsafe fn setRequiredSourceSampleDataTrackIDs(
            &self,
            required_source_sample_data_track_i_ds: &NSArray<NSNumber>,
        );
    }
);

extern_methods!(
    /// Methods declared on superclass `NSObject`
    unsafe impl AVMutableVideoCompositionInstruction {
        #[method_id(init)]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[method_id(new)]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    }
);

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionlayerinstruction?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVVideoCompositionLayerInstruction;
);

unsafe impl NSCoding for AVVideoCompositionLayerInstruction {}

unsafe impl NSCopying for AVVideoCompositionLayerInstruction {}

unsafe impl CopyingHelper for AVVideoCompositionLayerInstruction {
    type Result = Self;
}

unsafe impl NSMutableCopying for AVVideoCompositionLayerInstruction {}

unsafe impl MutableCopyingHelper for AVVideoCompositionLayerInstruction {
    type Result = AVMutableVideoCompositionLayerInstruction;
}

unsafe impl NSObjectProtocol for AVVideoCompositionLayerInstruction {}

unsafe impl NSSecureCoding for AVVideoCompositionLayerInstruction {}

extern_methods!(
    unsafe impl AVVideoCompositionLayerInstruction {
        #[cfg(feature = "objc2-core-media")]
        #[method(trackID)]
        pub unsafe fn trackID(&self) -> CMPersistentTrackID;

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        #[method(getTransformRampForTime:startTransform:endTransform:timeRange:)]
        pub unsafe fn getTransformRampForTime_startTransform_endTransform_timeRange(
            &self,
            time: CMTime,
            start_transform: *mut CGAffineTransform,
            end_transform: *mut CGAffineTransform,
            time_range: *mut CMTimeRange,
        ) -> bool;

        #[cfg(feature = "objc2-core-media")]
        #[method(getOpacityRampForTime:startOpacity:endOpacity:timeRange:)]
        pub unsafe fn getOpacityRampForTime_startOpacity_endOpacity_timeRange(
            &self,
            time: CMTime,
            start_opacity: *mut c_float,
            end_opacity: *mut c_float,
            time_range: *mut CMTimeRange,
        ) -> bool;

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        #[method(getCropRectangleRampForTime:startCropRectangle:endCropRectangle:timeRange:)]
        pub unsafe fn getCropRectangleRampForTime_startCropRectangle_endCropRectangle_timeRange(
            &self,
            time: CMTime,
            start_crop_rectangle: *mut CGRect,
            end_crop_rectangle: *mut CGRect,
            time_range: *mut CMTimeRange,
        ) -> bool;
    }
);

extern_methods!(
    /// Methods declared on superclass `NSObject`
    unsafe impl AVVideoCompositionLayerInstruction {
        #[method_id(init)]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[method_id(new)]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    }
);

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositionlayerinstruction?language=objc)
    #[unsafe(super(AVVideoCompositionLayerInstruction, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVMutableVideoCompositionLayerInstruction;
);

unsafe impl NSCoding for AVMutableVideoCompositionLayerInstruction {}

unsafe impl NSCopying for AVMutableVideoCompositionLayerInstruction {}

unsafe impl CopyingHelper for AVMutableVideoCompositionLayerInstruction {
    type Result = AVVideoCompositionInstruction;
}

unsafe impl NSMutableCopying for AVMutableVideoCompositionLayerInstruction {}

unsafe impl MutableCopyingHelper for AVMutableVideoCompositionLayerInstruction {
    type Result = Self;
}

unsafe impl NSObjectProtocol for AVMutableVideoCompositionLayerInstruction {}

unsafe impl NSSecureCoding for AVMutableVideoCompositionLayerInstruction {}

extern_methods!(
    unsafe impl AVMutableVideoCompositionLayerInstruction {
        #[cfg(feature = "AVAssetTrack")]
        #[method_id(videoCompositionLayerInstructionWithAssetTrack:)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionLayerInstructionWithAssetTrack(
            track: &AVAssetTrack,
        ) -> Retained<Self>;

        #[method_id(videoCompositionLayerInstruction)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionLayerInstruction() -> Retained<Self>;

        #[cfg(feature = "objc2-core-media")]
        #[method(trackID)]
        pub unsafe fn trackID(&self) -> CMPersistentTrackID;

        #[cfg(feature = "objc2-core-media")]
        /// Setter for [`trackID`][Self::trackID].
        #[method(setTrackID:)]
        pub unsafe fn setTrackID(&self, track_id: CMPersistentTrackID);

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        #[method(setTransformRampFromStartTransform:toEndTransform:timeRange:)]
        pub unsafe fn setTransformRampFromStartTransform_toEndTransform_timeRange(
            &self,
            start_transform: CGAffineTransform,
            end_transform: CGAffineTransform,
            time_range: CMTimeRange,
        );

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        #[method(setTransform:atTime:)]
        pub unsafe fn setTransform_atTime(&self, transform: CGAffineTransform, time: CMTime);

        #[cfg(feature = "objc2-core-media")]
        #[method(setOpacityRampFromStartOpacity:toEndOpacity:timeRange:)]
        pub unsafe fn setOpacityRampFromStartOpacity_toEndOpacity_timeRange(
            &self,
            start_opacity: c_float,
            end_opacity: c_float,
            time_range: CMTimeRange,
        );

        #[cfg(feature = "objc2-core-media")]
        #[method(setOpacity:atTime:)]
        pub unsafe fn setOpacity_atTime(&self, opacity: c_float, time: CMTime);

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        #[method(setCropRectangleRampFromStartCropRectangle:toEndCropRectangle:timeRange:)]
        pub unsafe fn setCropRectangleRampFromStartCropRectangle_toEndCropRectangle_timeRange(
            &self,
            start_crop_rectangle: CGRect,
            end_crop_rectangle: CGRect,
            time_range: CMTimeRange,
        );

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        #[method(setCropRectangle:atTime:)]
        pub unsafe fn setCropRectangle_atTime(&self, crop_rectangle: CGRect, time: CMTime);
    }
);

extern_methods!(
    /// Methods declared on superclass `NSObject`
    unsafe impl AVMutableVideoCompositionLayerInstruction {
        #[method_id(init)]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[method_id(new)]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    }
);

extern_class!(
    /// An AVVideoComposition object represents an immutable video composition.
    ///
    ///
    /// A video composition describes, for any time in the aggregate time range of its instructions, the number and IDs of video tracks that are to be used in order to produce a composed video frame corresponding to that time. When AVFoundation's built-in video compositor is used, the instructions an AVVideoComposition contain can specify a spatial transformation, an opacity value, and a cropping rectangle for each video source, and these can vary over time via simple linear ramping functions.
    ///
    /// A client can implement their own custom video compositor by implementing the AVVideoCompositing protocol; a custom video compositor is provided with pixel buffers for each of its video sources during playback and other operations and can perform arbitrary graphical operations on them in order to produce visual output.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositioncoreanimationtool?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVVideoCompositionCoreAnimationTool;
);

unsafe impl NSObjectProtocol for AVVideoCompositionCoreAnimationTool {}

extern_methods!(
    unsafe impl AVVideoCompositionCoreAnimationTool {
        #[cfg(all(feature = "objc2-core-media", feature = "objc2-quartz-core"))]
        #[cfg(not(target_os = "watchos"))]
        /// Add a Core Animation layer to the video composition
        ///
        /// Include a Core Animation layer as an individual track input in video composition.
        /// This layer should not come from, or be added to, another layer tree.
        /// trackID should not match any real trackID in the source. Use -[AVAsset unusedTrackID]
        /// to obtain a trackID that's guaranteed not to coincide with the trackID of any track of the asset.
        /// AVVideoCompositionInstructions should reference trackID where the rendered animation should be included.
        /// For best performance, no transform should be set in the AVVideoCompositionLayerInstruction for this trackID.
        /// Be aware that on iOS, CALayers backing a UIView usually have their content flipped (as defined by the
        /// -contentsAreFlipped method). It may be required to insert a CALayer with its geometryFlipped property set
        /// to YES in the layer hierarchy to get the same result when attaching a CALayer to a AVVideoCompositionCoreAnimationTool
        /// as when using it to back a UIView.
        #[method_id(videoCompositionCoreAnimationToolWithAdditionalLayer:asTrackID:)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionCoreAnimationToolWithAdditionalLayer_asTrackID(
            layer: &CALayer,
            track_id: CMPersistentTrackID,
        ) -> Retained<Self>;

        #[cfg(feature = "objc2-quartz-core")]
        #[cfg(not(target_os = "watchos"))]
        /// Compose the composited video frames with the Core Animation layer
        ///
        /// Place composited video frames in videoLayer and render animationLayer
        /// to produce the final frame. Normally videoLayer should be in animationLayer's sublayer tree.
        /// The animationLayer should not come from, or be added to, another layer tree.
        /// Be aware that on iOS, CALayers backing a UIView usually have their content flipped (as defined by the
        /// -contentsAreFlipped method). It may be required to insert a CALayer with its geometryFlipped property set
        /// to YES in the layer hierarchy to get the same result when attaching a CALayer to a AVVideoCompositionCoreAnimationTool
        /// as when using it to back a UIView.
        #[method_id(videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayer:inLayer:)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayer_inLayer(
            video_layer: &CALayer,
            animation_layer: &CALayer,
        ) -> Retained<Self>;

        #[cfg(feature = "objc2-quartz-core")]
        #[cfg(not(target_os = "watchos"))]
        /// Compose the composited video frames with the Core Animation layer
        ///
        /// Duplicate the composited video frames in each videoLayer and render animationLayer
        /// to produce the final frame. Normally videoLayers should be in animationLayer's sublayer tree.
        /// The animationLayer should not come from, or be added to, another layer tree.
        /// Be aware that on iOS, CALayers backing a UIView usually have their content flipped (as defined by the
        /// -contentsAreFlipped method). It may be required to insert a CALayer with its geometryFlipped property set
        /// to YES in the layer hierarchy to get the same result when attaching a CALayer to a AVVideoCompositionCoreAnimationTool
        /// as when using it to back a UIView.
        #[method_id(videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayers:inLayer:)]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayers_inLayer(
            video_layers: &NSArray<CALayer>,
            animation_layer: &CALayer,
        ) -> Retained<Self>;
    }
);

extern_methods!(
    /// Methods declared on superclass `NSObject`
    unsafe impl AVVideoCompositionCoreAnimationTool {
        #[method_id(init)]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[method_id(new)]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    }
);

extern_methods!(
    /// AVAssetVideoCompositionUtility
    #[cfg(feature = "AVAsset")]
    unsafe impl AVAsset {
        #[cfg(feature = "objc2-core-media")]
        #[deprecated = "Use findUnusedTrackIDWithCompletionHandler: instead"]
        #[method(unusedTrackID)]
        pub unsafe fn unusedTrackID(&self) -> CMPersistentTrackID;

        #[cfg(all(feature = "block2", feature = "objc2-core-media"))]
        /// Loads a track ID that will not collide with any existing track
        ///
        /// Parameter `completionHandler`: A block that is invoked when loading is complete, vending the track ID or an error.
        #[method(findUnusedTrackIDWithCompletionHandler:)]
        pub unsafe fn findUnusedTrackIDWithCompletionHandler(
            &self,
            completion_handler: &block2::Block<dyn Fn(CMPersistentTrackID, *mut NSError)>,
        );
    }
);

extern_methods!(
    /// AVVideoCompositionValidation
    unsafe impl AVVideoComposition {
        #[cfg(all(feature = "AVAsset", feature = "objc2-core-media"))]
        /// Indicates whether the timeRanges of the receiver's instructions conform to the requirements described for them immediately above (in connection with the instructions property) and also whether all of the layer instructions have a value for trackID that corresponds either to a track of the specified asset or to the receiver's animationTool.
        ///
        /// Parameter `asset`: Pass a reference to an AVAsset if you wish to validate the timeRanges of the instructions against the duration of the asset and the trackIDs of the layer instructions against the asset's tracks. Pass nil to skip that validation. Clients should ensure that the keys
        /// "
        /// tracks" and @"duration" are already loaded on the AVAsset before validation is attempted.
        ///
        /// Parameter `timeRange`: A CMTimeRange.  Only those instructions with timeRanges that overlap with the specified timeRange will be validated. To validate all instructions that may be used for playback or other processing, regardless of timeRange, pass CMTimeRangeMake(kCMTimeZero, kCMTimePositiveInfinity).
        ///
        /// Parameter `validationDelegate`: Indicates an object implementing the AVVideoCompositionValidationHandling protocol to receive information about troublesome portions of a video composition during processing of -isValidForAsset:. May be nil.
        ///
        /// In the course of validation, the receiver will invoke its validationDelegate with reference to any trouble spots in the video composition.
        /// An exception will be raised if the delegate modifies the receiver's array of instructions or the array of layerInstructions of any AVVideoCompositionInstruction contained therein during validation.
        #[deprecated = "Use isValidForTracks:assetDuration:timeRange:validationDelegate: instead"]
        #[method(isValidForAsset:timeRange:validationDelegate:)]
        pub unsafe fn isValidForAsset_timeRange_validationDelegate(
            &self,
            asset: Option<&AVAsset>,
            time_range: CMTimeRange,
            validation_delegate: Option<&ProtocolObject<dyn AVVideoCompositionValidationHandling>>,
        ) -> bool;

        #[cfg(all(feature = "AVAsset", feature = "block2", feature = "objc2-core-media"))]
        /// Determines whether the timeRanges of the receiver's instructions conform to the requirements described for them immediately above (in connection with the instructions property) and also whether all of the layer instructions have a value for trackID that corresponds either to a track of the specified asset or to the receiver's animationTool.
        ///
        /// Parameter `asset`: Pass a reference to an AVAsset if you wish to validate the timeRanges of the instructions against the duration of the asset and the trackIDs of the layer instructions against the asset's tracks. Pass nil to skip that validation.
        ///
        /// Parameter `timeRange`: A CMTimeRange.  Only those instructions with timeRanges that overlap with the specified timeRange will be validated. To validate all instructions that may be used for playback or other processing, regardless of timeRange, pass CMTimeRangeMake(kCMTimeZero, kCMTimePositiveInfinity).
        ///
        /// Parameter `validationDelegate`: Indicates an object implementing the AVVideoCompositionValidationHandling protocol to receive information about troublesome portions of a video composition during processing of -determineValidityForAsset:. May be nil.
        ///
        /// Parameter `completionHandler`: A block that is invoked when a determination is made about whether the video composition is valid.  If the `isValid` parameter is NO, either the video composition is not valid, in which case the `error` parameter will be nil, or the answer could not be determined, in which case the `error` parameter will be non-nil and describe the failure that occurred.
        ///
        /// In the course of validation, the receiver will invoke its validationDelegate with reference to any trouble spots in the video composition.
        /// An exception will be raised if the delegate modifies the receiver's array of instructions or the array of layerInstructions of any AVVideoCompositionInstruction contained therein during validation.
        #[deprecated]
        #[method(determineValidityForAsset:timeRange:validationDelegate:completionHandler:)]
        pub unsafe fn determineValidityForAsset_timeRange_validationDelegate_completionHandler(
            &self,
            asset: Option<&AVAsset>,
            time_range: CMTimeRange,
            validation_delegate: Option<&ProtocolObject<dyn AVVideoCompositionValidationHandling>>,
            completion_handler: &block2::Block<dyn Fn(Bool, *mut NSError)>,
        );

        #[cfg(all(feature = "AVAssetTrack", feature = "objc2-core-media"))]
        /// Indicates whether the timeRanges of the receiver's instructions conform to the requirements described for them immediately above (in connection with the instructions property) and also whether all of the layer instructions have a value for trackID that corresponds either to a track of the specified asset or to the receiver's animationTool.
        ///
        /// Parameter `tracks`: Pass a reference to an AVAsset's tracks if you wish to validate the trackIDs of the layer instructions against the asset's tracks. Pass nil to skip that validation. This method throws an exception if the tracks are not all from the same asset.
        ///
        /// Parameter `duration`: Pass an AVAsset if you wish to validate the timeRanges of the instructions against the duration of the asset. Pass kCMTimeInvalid to skip that validation.
        ///
        /// Parameter `timeRange`: A CMTimeRange.  Only those instructions with timeRanges that overlap with the specified timeRange will be validated. To validate all instructions that may be used for playback or other processing, regardless of timeRange, pass CMTimeRangeMake(kCMTimeZero, kCMTimePositiveInfinity).
        ///
        /// Parameter `validationDelegate`: Indicates an object implementing the AVVideoCompositionValidationHandling protocol to receive information about troublesome portions of a video composition during processing of -isValidForAsset:. May be nil.
        ///
        /// In the course of validation, the receiver will invoke its validationDelegate with reference to any trouble spots in the video composition.
        /// An exception will be raised if the delegate modifies the receiver's array of instructions or the array of layerInstructions of any AVVideoCompositionInstruction contained therein during validation.
        #[method(isValidForTracks:assetDuration:timeRange:validationDelegate:)]
        pub unsafe fn isValidForTracks_assetDuration_timeRange_validationDelegate(
            &self,
            tracks: &NSArray<AVAssetTrack>,
            duration: CMTime,
            time_range: CMTimeRange,
            validation_delegate: Option<&ProtocolObject<dyn AVVideoCompositionValidationHandling>>,
        ) -> bool;
    }
);

extern_protocol!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionvalidationhandling?language=objc)
    pub unsafe trait AVVideoCompositionValidationHandling: NSObjectProtocol {
        /// Invoked by an instance of AVVideoComposition when validating an instance of AVVideoComposition, to report a key that has an invalid value.
        ///
        /// Returns: An indication of whether the AVVideoComposition should continue validation in order to report additional problems that may exist.
        #[optional]
        #[method(videoComposition:shouldContinueValidatingAfterFindingInvalidValueForKey:)]
        unsafe fn videoComposition_shouldContinueValidatingAfterFindingInvalidValueForKey(
            &self,
            video_composition: &AVVideoComposition,
            key: &NSString,
        ) -> bool;

        #[cfg(feature = "objc2-core-media")]
        /// Invoked by an instance of AVVideoComposition when validating an instance of AVVideoComposition, to report a timeRange that has no corresponding video composition instruction.
        ///
        /// Returns: An indication of whether the AVVideoComposition should continue validation in order to report additional problems that may exist.
        #[optional]
        #[method(videoComposition:shouldContinueValidatingAfterFindingEmptyTimeRange:)]
        unsafe fn videoComposition_shouldContinueValidatingAfterFindingEmptyTimeRange(
            &self,
            video_composition: &AVVideoComposition,
            time_range: CMTimeRange,
        ) -> bool;

        #[cfg(feature = "AVVideoCompositing")]
        /// Invoked by an instance of AVVideoComposition when validating an instance of AVVideoComposition, to report a video composition instruction with a timeRange that's invalid, that overlaps with the timeRange of a prior instruction, or that contains times earlier than the timeRange of a prior instruction.
        ///
        /// Use CMTIMERANGE_IS_INVALID, defined in CMTimeRange.h, to test whether the timeRange itself is invalid. Refer to headerdoc for AVVideoComposition.instructions for a discussion of how timeRanges for instructions must be formulated.
        ///
        /// Returns: An indication of whether the AVVideoComposition should continue validation in order to report additional problems that may exist.
        #[optional]
        #[method(videoComposition:shouldContinueValidatingAfterFindingInvalidTimeRangeInInstruction:)]
        unsafe fn videoComposition_shouldContinueValidatingAfterFindingInvalidTimeRangeInInstruction(
            &self,
            video_composition: &AVVideoComposition,
            video_composition_instruction: &ProtocolObject<
                dyn AVVideoCompositionInstructionProtocol,
            >,
        ) -> bool;

        #[cfg(all(feature = "AVAsset", feature = "AVVideoCompositing"))]
        /// Invoked by an instance of AVVideoComposition when validating an instance of AVVideoComposition, to report a video composition layer instruction with a trackID that does not correspond either to the trackID used for the composition's animationTool or to a track of the asset specified in -[AVVideoComposition isValidForAsset:timeRange:delegate:].
        ///
        /// Returns: An indication of whether the AVVideoComposition should continue validation in order to report additional problems that may exist.
        #[optional]
        #[method(videoComposition:shouldContinueValidatingAfterFindingInvalidTrackIDInInstruction:layerInstruction:asset:)]
        unsafe fn videoComposition_shouldContinueValidatingAfterFindingInvalidTrackIDInInstruction_layerInstruction_asset(
            &self,
            video_composition: &AVVideoComposition,
            video_composition_instruction: &ProtocolObject<
                dyn AVVideoCompositionInstructionProtocol,
            >,
            layer_instruction: &AVVideoCompositionLayerInstruction,
            asset: &AVAsset,
        ) -> bool;
    }
);
