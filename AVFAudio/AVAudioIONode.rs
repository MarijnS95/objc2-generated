//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-audio-toolbox")]
#[cfg(not(target_os = "watchos"))]
use objc2_audio_toolbox::*;
#[cfg(feature = "objc2-core-audio-types")]
use objc2_core_audio_types::*;
use objc2_foundation::*;

use crate::*;

/// [Apple's documentation](https://developer.apple.com/documentation/avfaudio/avaudioionodeinputblock?language=objc)
#[cfg(all(
    feature = "AVAudioTypes",
    feature = "block2",
    feature = "objc2-core-audio-types"
))]
pub type AVAudioIONodeInputBlock =
    *mut block2::Block<dyn Fn(AVAudioFrameCount) -> *mut AudioBufferList>;

/// [Apple's documentation](https://developer.apple.com/documentation/avfaudio/avaudiovoiceprocessingspeechactivityevent?language=objc)
// NS_ENUM
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct AVAudioVoiceProcessingSpeechActivityEvent(pub NSInteger);
impl AVAudioVoiceProcessingSpeechActivityEvent {
    pub const AVAudioVoiceProcessingSpeechActivityStarted: Self = Self(0);
    pub const AVAudioVoiceProcessingSpeechActivityEnded: Self = Self(1);
}

unsafe impl Encode for AVAudioVoiceProcessingSpeechActivityEvent {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

unsafe impl RefEncode for AVAudioVoiceProcessingSpeechActivityEvent {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// [Apple's documentation](https://developer.apple.com/documentation/avfaudio/avaudiovoiceprocessingotheraudioduckinglevel?language=objc)
// NS_ENUM
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct AVAudioVoiceProcessingOtherAudioDuckingLevel(pub NSInteger);
impl AVAudioVoiceProcessingOtherAudioDuckingLevel {
    #[doc(alias = "AVAudioVoiceProcessingOtherAudioDuckingLevelDefault")]
    pub const Default: Self = Self(0);
    #[doc(alias = "AVAudioVoiceProcessingOtherAudioDuckingLevelMin")]
    pub const Min: Self = Self(10);
    #[doc(alias = "AVAudioVoiceProcessingOtherAudioDuckingLevelMid")]
    pub const Mid: Self = Self(20);
    #[doc(alias = "AVAudioVoiceProcessingOtherAudioDuckingLevelMax")]
    pub const Max: Self = Self(30);
}

unsafe impl Encode for AVAudioVoiceProcessingOtherAudioDuckingLevel {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

unsafe impl RefEncode for AVAudioVoiceProcessingOtherAudioDuckingLevel {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfaudio/avaudioionode?language=objc)
    #[unsafe(super(AVAudioNode, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(feature = "AVAudioNode")]
    pub struct AVAudioIONode;
);

#[cfg(feature = "AVAudioNode")]
unsafe impl NSObjectProtocol for AVAudioIONode {}

extern_methods!(
    #[cfg(feature = "AVAudioNode")]
    unsafe impl AVAudioIONode {
        #[method(presentationLatency)]
        pub unsafe fn presentationLatency(&self) -> NSTimeInterval;

        #[cfg(feature = "objc2-audio-toolbox")]
        #[cfg(not(target_os = "watchos"))]
        #[method(audioUnit)]
        pub unsafe fn audioUnit(&self) -> AudioUnit;

        #[method(isVoiceProcessingEnabled)]
        pub unsafe fn isVoiceProcessingEnabled(&self) -> bool;

        #[method(setVoiceProcessingEnabled:error:_)]
        pub unsafe fn setVoiceProcessingEnabled_error(
            &self,
            enabled: bool,
        ) -> Result<(), Retained<NSError>>;
    }
);

extern_methods!(
    /// Methods declared on superclass `NSObject`
    #[cfg(feature = "AVAudioNode")]
    unsafe impl AVAudioIONode {
        #[method_id(@__retain_semantics Init init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[method_id(@__retain_semantics New new)]
        pub unsafe fn new() -> Retained<Self>;
    }
);

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfaudio/avaudioinputnode?language=objc)
    #[unsafe(super(AVAudioIONode, AVAudioNode, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(feature = "AVAudioNode")]
    pub struct AVAudioInputNode;
);

#[cfg(all(feature = "AVAudioMixing", feature = "AVAudioNode"))]
unsafe impl AVAudio3DMixing for AVAudioInputNode {}

#[cfg(all(feature = "AVAudioMixing", feature = "AVAudioNode"))]
unsafe impl AVAudioMixing for AVAudioInputNode {}

#[cfg(all(feature = "AVAudioMixing", feature = "AVAudioNode"))]
unsafe impl AVAudioStereoMixing for AVAudioInputNode {}

#[cfg(feature = "AVAudioNode")]
unsafe impl NSObjectProtocol for AVAudioInputNode {}

extern_methods!(
    #[cfg(feature = "AVAudioNode")]
    unsafe impl AVAudioInputNode {
        #[method_id(@__retain_semantics Init init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[cfg(all(
            feature = "AVAudioFormat",
            feature = "AVAudioTypes",
            feature = "block2",
            feature = "objc2-core-audio-types"
        ))]
        #[method(setManualRenderingInputPCMFormat:inputBlock:)]
        pub unsafe fn setManualRenderingInputPCMFormat_inputBlock(
            &self,
            format: &AVAudioFormat,
            block: AVAudioIONodeInputBlock,
        ) -> bool;

        #[method(isVoiceProcessingBypassed)]
        pub unsafe fn isVoiceProcessingBypassed(&self) -> bool;

        #[method(setVoiceProcessingBypassed:)]
        pub unsafe fn setVoiceProcessingBypassed(&self, voice_processing_bypassed: bool);

        #[method(isVoiceProcessingAGCEnabled)]
        pub unsafe fn isVoiceProcessingAGCEnabled(&self) -> bool;

        #[method(setVoiceProcessingAGCEnabled:)]
        pub unsafe fn setVoiceProcessingAGCEnabled(&self, voice_processing_agc_enabled: bool);

        #[method(isVoiceProcessingInputMuted)]
        pub unsafe fn isVoiceProcessingInputMuted(&self) -> bool;

        #[method(setVoiceProcessingInputMuted:)]
        pub unsafe fn setVoiceProcessingInputMuted(&self, voice_processing_input_muted: bool);

        #[cfg(feature = "block2")]
        #[method(setMutedSpeechActivityEventListener:)]
        pub unsafe fn setMutedSpeechActivityEventListener(
            &self,
            listener_block: Option<
                &block2::Block<dyn Fn(AVAudioVoiceProcessingSpeechActivityEvent)>,
            >,
        ) -> bool;
    }
);

extern_methods!(
    /// Methods declared on superclass `NSObject`
    #[cfg(feature = "AVAudioNode")]
    unsafe impl AVAudioInputNode {
        #[method_id(@__retain_semantics New new)]
        pub unsafe fn new() -> Retained<Self>;
    }
);

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfaudio/avaudiooutputnode?language=objc)
    #[unsafe(super(AVAudioIONode, AVAudioNode, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(feature = "AVAudioNode")]
    pub struct AVAudioOutputNode;
);

#[cfg(feature = "AVAudioNode")]
unsafe impl NSObjectProtocol for AVAudioOutputNode {}

extern_methods!(
    #[cfg(feature = "AVAudioNode")]
    unsafe impl AVAudioOutputNode {
        #[method_id(@__retain_semantics Init init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;
    }
);

extern_methods!(
    /// Methods declared on superclass `NSObject`
    #[cfg(feature = "AVAudioNode")]
    unsafe impl AVAudioOutputNode {
        #[method_id(@__retain_semantics New new)]
        pub unsafe fn new() -> Retained<Self>;
    }
);
